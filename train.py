#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Apr  1 16:20:36 2020

@author: ben
"""


import imgaug.augmenters as iaa # https://github.com/aleju/imgaug (pip3 install imageaug)

from mrcnn.config import Config
from mrcnn import model as modellib
from mrcnn import visualize
import mrcnn
from mrcnn.utils import Dataset
from mrcnn.model import MaskRCNN
import numpy as np
from numpy import zeros
from numpy import asarray
import colorsys
import argparse
import imutils
import random
import cv2
import os
import time
from matplotlib import pyplot
from matplotlib.patches import Rectangle
from keras.models import load_model
%matplotlib inline
from os import listdir
from xml.etree import ElementTree
from sklearn.model_selection import train_test_split
from mrcnn import utils
from mrcnn.model import log
from mrcnn.utils import compute_ap




class myMaskRCNNConfig(Config):
    # give the configuration a recognizable name
    NAME = "MaskRCNN_config"
 
    # set the number of GPUs to use along with the number of images
    # per GPU
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
 
    # number of classes (we would normally add +1 for the background)
     # kangaroo + BG
    NUM_CLASSES = 1+10
   
    # Number of training steps per epoch
    STEPS_PER_EPOCH = 1200
    
    # Learning rate
    LEARNING_RATE=0.001 # as opposed to 0.001
    
    # Skip detections with < 90% confidence
    DETECTION_MIN_CONFIDENCE = 0.8
    #WEIGHT_DECAY = 0.003
    # setting Max ground truth instances
    MAX_GT_INSTANCES=10
    # Number of validation steps to run at the end of every training epoch.
    # A bigger number improves accuracy of validation stats, but slows
    # down the training.
    VALIDATION_STEPS = 60

    # Backbone network architecture
    # Supported values are: resnet50, resnet101.
    # You can also provide a callable that should have the signature
    # of model.resnet_graph. If you do so, you need to supply a callable
    # to COMPUTE_BACKBONE_SHAPE as well
    BACKBONE = "resnet101"
    # Max number of final detections
    DETECTION_MAX_INSTANCES = 6
    # Use RPN ROIs or externally generated ROIs for training
    # Keep this True for most situations. Set to False if you want to train
    # the head branches on ROI generated by code rather than the ROIs from
    # the RPN. For example, to debug the classifier head without having to
    # train the RPN.
    USE_RPN_ROIS = True
    OPTIMIZER = "ADAM"
    TRAIN_ROIS_PER_IMAGE = 512
 
#mean_average_precision_callback = modellib.MeanAveragePrecisionCallback(model,model_inference, test_set, calculate_map_at_every_X_epoch=1, verbose=1)

class RoadDataset(Dataset):
    # load the dataset definitions
    def load_dataset(self, dataset_dir, is_train=True):
        
        #  Add classes. We have only one class to add.
        image_id_reference = []
        self.add_class("damage", 1, "D00")
        self.add_class("damage", 2, "D01")
        self.add_class("damage", 3, "D10")
        self.add_class("damage", 4, "D11")
        self.add_class("damage", 5, "D20")
        self.add_class("damage", 6, "D40")      
        self.add_class("damage", 7, "D43")
        self.add_class("damage", 8, "D44")        
        self.add_class("damage", 9, "general_damage")    
        self.add_class("damage", 10, "D50")
        # define data locations for images and annotations
        images_dir = "/images/"
        annotations_dir = "/annotations/"
        dir2 = dataset_dir + "/annotations/"
        train_dir1 =open(os.path.join(dir2, "train.txt"),'r')
        train_dir = train_dir1.readlines()
        val_dir1 =open(os.path.join(dir2, "val.txt"),'r')
        val_dir = val_dir1.readlines()
        # Iterate through all files in the folder to 
        #add class, images and annotaions
        classes = ["D00","D01","D10","D11","D20", "D40", "D43", "D44", "D50"]
        j = 0
        k = 0
        if is_train == True:
            for i in range (len(train_dir)):
                try:
                    class_type = ""
                    image_id = train_dir[j]
                    image_id = image_id.rstrip('\n')
                    img_path = "/home/anugunj.naman/sih2020/RoadDamageDatasetV2/images/" + str(image_id) + ".jpg"
                    ann_path = "/home/anugunj.naman/sih2020/RoadDamageDatasetV2/annotations/xmls/" + str(image_id) + '.xml'
                    class_type = self.extract_type(str(image_id))
                    # adding images and annotations to dataset
                    """
                    if class_type in classes:
                        #class_type = "general_damage"
                        self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = class_type)
                    """
                    if class_type in classes:
                        #class_type = "general_damage"
                        if class_type == "D00":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D00")
                        if class_type == "D01":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D01")
                        if class_type == "D10":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D10")
                        if class_type == "D11":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D11")
                        if class_type == "D20":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D20")
                        if class_type == "D40":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D40")
                        if class_type == "D50":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D50")
                        if class_type == "D43":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D43")
                        if class_type == "D44":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D44")
                    else:
                        self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "general_damage")
                    j = j+1
                except Exception as e:
                    print("error in: " + image_id)
        elif is_train == False:
            for i in range (len(val_dir)):
                try:
                    class_type = ""
                    image_id = val_dir[j]
                    image_id = image_id.rstrip('\n')
                    img_path = "/home/anugunj.naman/sih2020/RoadDamageDatasetV2/images/" + str(image_id) + ".jpg"
                    ann_path = "/home/anugunj.naman/sih2020/RoadDamageDatasetV2/annotations/xmls/" + str(image_id) + '.xml'
                    class_type = self.extract_type(str(image_id))
                    # adding images and annotations to dataset
                    """
                    if class_type in classes:
                        #class_type = "general_damage"
                        self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = class_type)
                    """
                    if class_type in classes:
                        #class_type = "general_damage"
                        if class_type == "D00":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D00")
                        if class_type == "D01":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D01")
                        if class_type == "D10":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D10")
                        if class_type == "D11":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D11")
                        if class_type == "D20":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D20")
                        if class_type == "D40":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D40")
                        if class_type == "D50":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D50")
                        if class_type == "D43":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D43")
                        if class_type == "D44":
                            self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "D44")
                    else:
                        self.add_image("damage", image_id=image_id, path=img_path, annotation=ann_path, class_ids = "general_damage")
                    j = j+1
                except Exception as e:
                    print("error in: " + image_id) 
    # extract bounding boxes from an annotation file
    def extract_type(self, file):
        if file =='.DS_Store':
            pass
        else:
            infile_xml = open("/home/anugunj.naman/sih2020/RoadDamageDatasetV2/annotations/xmls/" + file + ".xml")
            tree = ElementTree.parse(infile_xml)
            root = tree.getroot()
            cls_names = list()
            for obj in root.iter('object'):
                cls_name = obj.find('name').text
                cls_names.append(cls_name)
            #print(cls_names)
            return cls_names       
    # extract bounding boxes from an annotation file
    def extract_type2(self, file):
        if file =='.DS_Store':
            pass
        else:
            infile_xml = open(file)
            tree = ElementTree.parse(infile_xml)
            root = tree.getroot()
            cls_names = list()
            for obj in root.findall('.//object'):
                cls_name = obj.find('name').text
                cls_names.append(cls_name)
            #print(cls_names)
            return cls_names      
    # extract bounding boxes from an annotation file
    def extract_boxes(self, filename):
        
        # load and parse the file
        tree = ElementTree.parse(filename)
        # get the root of the document
        root = tree.getroot()
        
        # extract each bounding box
        class_type = self.extract_type2(filename)
        boxes = list()
        i = 0
        for box in root.findall('.//bndbox'):
            xmin = int(box.find('xmin').text)
            ymin = int(box.find('ymin').text)
            xmax = int(box.find('xmax').text)
            ymax = int(box.find('ymax').text)
            
            
            #print(class_type[i])
            coors = [xmin, ymin, xmax, ymax, class_type[i]]
            boxes.append(coors)
            #print(str(boxes))
            i = i +1
        
        # extract image dimensions
        width = int(root.find('.//size/width').text)
        height = int(root.find('.//size/height').text)
        return boxes, width, height
    # load the masks for an image
    
    def load_mask(self, image_id):
        # get details of image
        info = self.image_info[image_id]
        name = info['id']
        # define anntation  file location
        path = info['annotation']
        class_name = self.extract_type(name)
        # load XML
        boxes, w, h = self.extract_boxes(path)
       
        """
        THIS IS THE PROBLEM FUNCTION
        """
        
        
        # create one array for all masks, each on a different channel
        masks = zeros([h, w, len(boxes)], dtype='uint8')
        class_ids = list()
        for i in range(len(boxes)):
            box = boxes[i]
            row_s, row_e = box[1], box[3]
            col_s, col_e = box[0], box[2]
            class_type = box[4]
            #print(box[4])
            if (class_type == 'D00'):
                masks[row_s:row_e, col_s:col_e, i] = 1
                class_ids.append(self.class_names.index('D00'))
            if (class_type == 'D01'):
                masks[row_s:row_e, col_s:col_e, i] = 2
                class_ids.append(self.class_names.index('D01'))  
            if (class_type == 'D10'):
                masks[row_s:row_e, col_s:col_e, i] = 3
                class_ids.append(self.class_names.index('D10'))
            if (class_type == 'D11'):
                masks[row_s:row_e, col_s:col_e, i] = 4
                class_ids.append(self.class_names.index('D11'))
            if (class_type == 'D20'):
                masks[row_s:row_e, col_s:col_e, i] = 5
                class_ids.append(self.class_names.index('D20'))
            if (class_type == 'D40'):
                masks[row_s:row_e, col_s:col_e, i] = 6
                class_ids.append(self.class_names.index('D40'))
            if (class_type == 'D43'):
                masks[row_s:row_e, col_s:col_e, i] = 7
                class_ids.append(self.class_names.index('D43'))
            if (class_type == 'D44'):
                masks[row_s:row_e, col_s:col_e, i] = 8
                class_ids.append(self.class_names.index('D44'))
            if (class_type == 'general_damage'):
                masks[row_s:row_e, col_s:col_e, i] = 9
                class_ids.append(self.class_names.index('general_damage'))
            if (class_type == 'D50'):
                masks[row_s:row_e, col_s:col_e, i] = 10
                class_ids.append(self.class_names.index('D50'))
        return masks, asarray(class_ids, dtype='int32')
        """
        
        
        # create masks
        class_ids = list()
        for i in range(len(boxes)):
            box = boxes[i]
            row_s, row_e = box[1], box[3]
            col_s, col_e = box[0], box[2]
            masks[row_s:row_e, col_s:col_e, i] = 1
            
            if (box[4] == 'car'):
            masks[row_s:row_e, col_s:col_e, i] = 1
            class_ids.append(self.class_names.index('car'))
        else:
            masks[row_s:row_e, col_s:col_e, i] = 2
            class_ids.append(self.class_names.index('rider'))   
            
            
            
            
            class_ids.append(self.class_names.index('D00'))
            class_ids.append(self.class_names.index('D01'))
            class_ids.append(self.class_names.index('D10'))
            class_ids.append(self.class_names.index('D11'))
            class_ids.append(self.class_names.index('D20'))
            class_ids.append(self.class_names.index('D40'))
            class_ids.append(self.class_names.index('D43'))
            class_ids.append(self.class_names.index('D44'))
            class_ids.append(self.class_names.index('D50'))
            class_ids.append(self.class_names.index('general_damage'))
        """
        return masks, asarray(class_ids, dtype='int32')
        # load an image reference
        """Return the path of the image."""
    def image_reference(self, image_id):
        info = self.image_info[image_id]
        #print(info)
        return info['path']
    
    
# prepare test/val set
train_set = RoadDataset()
train_set.load_dataset("/home/anugunj.naman/sih2020/RoadDamageDatasetV2", is_train=True)
train_set.prepare()
print("Train: %d" % len(train_set.image_ids))
test_set = RoadDataset()
test_set.load_dataset("/home/anugunj.naman/sih2020/RoadDamageDatasetV2", is_train=False)
test_set.prepare()
print("Test: %d" % len(test_set.image_ids))


                        """Train New Model"""

   
config = myMaskRCNNConfig()
config.display()

# initialize the Mask R-CNN model for inference 
print("Loading Mask R-CNN model...")
model = modellib.MaskRCNN(mode="training", config=config, model_dir='./')
#n load the weights for COCO
#model.load_weights('/home/ben/Desktop/work/mask_rcnn_coco.h5', 
 #                  by_name=True, 
  #                 exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])
model.load_weights('/home/ben/Desktop/work/mask_rcnn_coco.h5', 
                   by_name=True, 
                   exclude=["mrcnn_class_logits", "mrcnn_bbox_fc",  "mrcnn_bbox", "mrcnn_mask"])
model.keras_model.summary()
#not using augmentation
"""
augmentation = iaa.Sometimes(.667, iaa.Sequential([
    iaa.Fliplr(0.5), # horizontal flips
    iaa.Crop(percent=(0, 0.1)), # random crops
    # Small gaussian blur with random sigma between 0 and 0.25.
    # But we only blur about 50% of all images.
    iaa.Sometimes(0.5,
        iaa.GaussianBlur(sigma=(0, 0.25))
    ),
    # Strengthen or weaken the contrast in each image.
    iaa.ContrastNormalization((0.75, 1.5)),
    # Add gaussian noise.
    # For 50% of all images, we sample the noise once per pixel.
    # For the other 50% of all images, we sample the noise per pixel AND
    # channel. This can change the color (not only brightness) of the
    # pixels.
    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255)),
    # Make some images brighter and some darker.
    # In 20% of all cases, we sample the multiplier once per channel,
    # which can end up changing the color of the images.
    iaa.Multiply((0.8, 1.2)),
    # Apply affine transformations to each image.
    # Scale/zoom them, translate/move them, rotate them and shear them.
    iaa.Affine(
        scale={"x": (0.8, 1.2), "y": (0.8, 1.2)},
        #translate_percent={"x": (-0.2, 0.2), "y": (-0.2, 0.2)},
        rotate=(-180, 180),
        #shear=(-8, 8)
    )
], random_order=True)) # apply augmenters in random order
"""
#augmentation = imgaug.augmenters.Fliplr(0.5)
#augmentation = imgaug.augmenters.Rot90(keep_size = True)
#mean_average_precision_callback = modellib.MeanAveragePrecisionCallback(model,model_inference, test_set, calculate_map_at_every_X_epoch=1, verbose=1)
#check

# Load and display random samples
#
#image_ids = np.random.choice(train_set.img_path, 4)
image_ids = np.random.choice(train_set.image_ids, 4)
for image_id in image_ids:
    image = train_set.load_image(image_id)
    mask, class_ids = train_set.load_mask(image_id)
    visualize.display_top_masks(image, mask, class_ids, train_set.class_names)

image_id = random.choice(train_set.image_ids)
image = train_set.load_image(image_id)
mask, class_ids = train_set.load_mask(image_id)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)


# Display image and additional stats
print("image_id ", image_id, train_set.image_reference(image_id))
log("image", image)
log("mask", mask)
log("class_ids", class_ids)
log("bbox", bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, train_set.class_names)
model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=2, layers='all') #,augmentation=augmentation

#lr = 0.0003
#model.train(train_set, test_set, learning_rate=lr, epochs=1, layers='heads') #,augmentation=augmentation

model_path = '/home/anugunj.naman/sih2020/RoadDamageDatasetV2/multi_classv4.h5'
model.keras_model.save_weights(model_path)



                    """Test Existing Model"""
                    
                    
model_path = '/home/anugunj.naman/sih2020/RoadDamageDatasetV2/multi_classv4.h5'
                    
# running model
# prepare config
config = myMaskRCNNConfig()
config.display()
# define the model
model = MaskRCNN(mode='inference', model_dir='./', config=config)

# load weights (mscoco) and exclude the output layers

model.load_weights(model_path, by_name=True)



image_id = random.choice(test_set.image_ids)

#image_id = "Muroran_20170907111030"
image, image_meta, gt_class_id, gt_bbox, gt_mask =    modellib.load_image_gt(test_set, config, image_id, use_mini_mask=False)
info = test_set.image_info[image_id]
print("image ID: {}.{} ({}) {}".format(info["source"], info["id"], image_id, 
                                       test_set.image_reference(image_id)))
# Run object detection
results = model.detect([image], verbose=1)

# Display results

r = results[0]
visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], 
                            test_set.class_names, r['scores'],
                            title="Predictions", name = "/home/anugunj.naman/sih2020/RoadDamageDatasetV2/test"
                            )


plt.savefig('/home/anugunj.naman/sih2020/RoadDamageDatasetV2/example.jpg',bbox_inches='tight')

#imagenet

